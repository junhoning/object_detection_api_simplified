{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\junhoning\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob \n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master = ''  # Name of the TensorFlow master to use.\n",
    "task = 0  # task id\n",
    "num_clones = 1  # Number of clones to deploy per worker.\n",
    "clone_on_cpu = False  # Force clones to be deployed on CPU.  Note that even if \n",
    "                      # set to False (allowing ops to run on gpu), some ops may\n",
    "                      # still be run on the CPU if they have no GPU kernel.\n",
    "worker_replicas = 1  # Number of worker+trainer replicas.\n",
    "ps_tasks = 0  # Number of parameter server tasks. If None, does not use a parameter server.\n",
    "train_dir = ''  # Directory to save the checkpoints and training summaries.\n",
    "pipeline_config_path = ''  # Directory to save the checkpoints and training summaries.\n",
    "train_config_path = ''  # Path to a pipeline_pb2.TrainEvalPipelineConfig config file. If provided, other configs are ignored\n",
    "input_config_path = ''  # Path to a train_pb2.TrainConfig config file.\n",
    "model_config_path = ''  # Path to a model_pb2.DetectionModel config file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert train_dir, '`train_dir` is missing.'\n",
    "if task == 0: tf.gfile.MakeDirs(train_dir)\n",
    "if pipeline_config_path:\n",
    "    configs = config_util.get_configs_from_pipeline_file(\n",
    "        pipeline_config_path)\n",
    "    if task == 0:\n",
    "        tf.gfile.Copy(FLAGS.pipeline_config_path,\n",
    "                      os.path.join(FLAGS.train_dir, 'pipeline.config'),\n",
    "                      overwrite=True)\n",
    "else:\n",
    "    configs = config_util.get_configs_from_multiple_files(\n",
    "        model_config_path=model_config_path,\n",
    "        train_config_path=train_config_path,\n",
    "        train_input_config_path=input_config_path)\n",
    "    if FLAGS.task == 0:\n",
    "        for name, config in [('model.config', model_config_path),\n",
    "                             ('train.config', train_config_path),\n",
    "                             ('input.config', input_config_path)]:\n",
    "            tf.gfile.Copy(config, os.path.join(train_dir, name),\n",
    "                          overwrite=True)\n",
    "\n",
    "model_config = configs['model']\n",
    "train_config = configs['train_config']\n",
    "input_config = configs['train_input_config']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
